episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,num_healthy_workers,num_agent_steps_sampled,num_agent_steps_trained,num_env_steps_sampled,num_env_steps_trained,num_env_steps_sampled_this_iter,num_env_steps_trained_this_iter,timesteps_total,agent_timesteps_total,done,episodes_total,training_iteration,trial_id,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,time_since_restore,timesteps_since_restore,iterations_since_restore,warmup_time,info/num_env_steps_sampled,info/num_env_steps_trained,info/num_agent_steps_sampled,info/num_agent_steps_trained,sampler_results/episode_reward_max,sampler_results/episode_reward_min,sampler_results/episode_reward_mean,sampler_results/episode_len_mean,sampler_results/episodes_this_iter,hist_stats/episode_reward,hist_stats/episode_lengths,sampler_perf/mean_raw_obs_processing_ms,sampler_perf/mean_inference_ms,sampler_perf/mean_action_processing_ms,sampler_perf/mean_env_wait_ms,sampler_perf/mean_env_render_ms,timers/training_iteration_time_ms,timers/load_time_ms,timers/load_throughput,timers/learn_time_ms,timers/learn_throughput,timers/update_time_ms,counters/num_env_steps_sampled,counters/num_env_steps_trained,counters/num_agent_steps_sampled,counters/num_agent_steps_trained,perf/cpu_util_percent,perf/ram_util_percent,sampler_results/hist_stats/episode_reward,sampler_results/hist_stats/episode_lengths,sampler_results/sampler_perf/mean_raw_obs_processing_ms,sampler_results/sampler_perf/mean_inference_ms,sampler_results/sampler_perf/mean_action_processing_ms,sampler_results/sampler_perf/mean_env_wait_ms,sampler_results/sampler_perf/mean_env_render_ms,info/learner/default_policy/learner_stats/cur_kl_coeff,info/learner/default_policy/learner_stats/cur_lr,info/learner/default_policy/learner_stats/total_loss,info/learner/default_policy/learner_stats/policy_loss,info/learner/default_policy/learner_stats/vf_loss,info/learner/default_policy/learner_stats/vf_explained_var,info/learner/default_policy/learner_stats/kl,info/learner/default_policy/learner_stats/entropy,info/learner/default_policy/learner_stats/entropy_coeff
-695.0,-920.0,-783.65,200.0,20,1,4000,4000,4000,4000,4000,4000,4000,4000,False,20,1,5c6e8_00000,d6df190c303a44f39815fbc8bb40239b,2022-07-08_07-26-12,1657257972,24.291654586791992,24.291654586791992,7347,sassauna2.ee.ethz.ch,129.132.4.155,24.291654586791992,0,1,19.458189010620117,4000,4000,4000,4000,-695.0,-920.0,-783.65,200.0,20,"[-821.0, -785.0, -695.0, -803.0, -920.0, -758.0, -794.0, -821.0, -830.0, -695.0, -803.0, -866.0, -740.0, -704.0, -713.0, -821.0, -740.0, -776.0, -749.0, -839.0]","[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]",0.08699531049854724,0.9684379146683668,0.05401053806448901,0.060492829959471806,0.0,24282.051,6.068,659170.831,19477.093,205.369,5.515,4000,4000,4000,4000,4.0685714285714285,8.708571428571426,"[-821.0, -785.0, -695.0, -803.0, -920.0, -758.0, -794.0, -821.0, -830.0, -695.0, -803.0, -866.0, -740.0, -704.0, -713.0, -821.0, -740.0, -776.0, -749.0, -839.0]","[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]",0.08699531049854724,0.9684379146683668,0.05401053806448901,0.060492829959471806,0.0,0.20000000000000004,5.0000000000000016e-05,9.938009441539805,-0.004262999953922405,9.941332631470054,0.00016407245589840797,0.0046990626813657975,1.787063112438366,0.0
-614.0,-920.0,-755.75,200.0,20,1,8000,8000,8000,8000,4000,4000,8000,8000,False,40,2,5c6e8_00000,d6df190c303a44f39815fbc8bb40239b,2022-07-08_07-26-36,1657257996,24.162128925323486,48.45378351211548,7347,sassauna2.ee.ethz.ch,129.132.4.155,48.45378351211548,0,2,19.458189010620117,8000,8000,8000,8000,-614.0,-920.0,-755.75,200.0,20,"[-821.0, -785.0, -695.0, -803.0, -920.0, -758.0, -794.0, -821.0, -830.0, -695.0, -803.0, -866.0, -740.0, -704.0, -713.0, -821.0, -740.0, -776.0, -749.0, -839.0, -731.0, -623.0, -758.0, -767.0, -614.0, -686.0, -740.0, -731.0, -713.0, -884.0, -668.0, -695.0, -794.0, -785.0, -731.0, -668.0, -749.0, -767.0, -686.0, -767.0]","[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]",0.08676380347736527,0.9660838839111253,0.05373849976323741,0.06037707321467913,0.0,24217.998,6.684,598406.22,19441.226,205.748,5.782,8000,8000,8000,8000,4.277142857142856,8.702857142857141,"[-821.0, -785.0, -695.0, -803.0, -920.0, -758.0, -794.0, -821.0, -830.0, -695.0, -803.0, -866.0, -740.0, -704.0, -713.0, -821.0, -740.0, -776.0, -749.0, -839.0, -731.0, -623.0, -758.0, -767.0, -614.0, -686.0, -740.0, -731.0, -713.0, -884.0, -668.0, -695.0, -794.0, -785.0, -731.0, -668.0, -749.0, -767.0, -686.0, -767.0]","[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]",0.08676380347736527,0.9660838839111253,0.05373849976323741,0.06037707321467913,0.0,0.10000000000000002,5.0000000000000016e-05,9.865345690327306,-0.02454911864572956,9.888607900886125,-0.00016797101625832178,0.01286913398362763,1.7572086204764663,0.0
